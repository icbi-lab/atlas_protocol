{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Merge datasets, harmonize annotations and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating single-cell RNA-seq datasets from multiple sources can provide numerous benefits, including increased statistical power, validation of findings across diverse conditions, and the identification of novel gene expression patterns that may be challenging to detect in individual datasets. However, the merging process presents two major challenges: harmonizing gene annotations and metadata across datasets to ensure consistency in downstream analyses.\n",
    "\n",
    ":::{note} gene annotations\n",
    "\n",
    "Ideally, access to raw FASTQ files would allow mapping to the same reference genome and annotations. However, in many cases, only processed data is available that may have been mapped to different genome annotations or versions. The two most commonly used gene annotation sources are GENCODE and Ensembl, which offer standardized gene models and annotations for various organisms. Best case scenario processed datasets have unique gene ids such as ensembl_ids, unfortunaetly often only gene symbols are provided that are not unique and can change across annotation versions and sources. sometimes provide only gene symbols.\n",
    "While it is possible to perform gene symbol-based integration, this approach is not always accurate, as gene symbols are not unique and can change between annotation versions. In contrast, before integrating the datasets we will map the available gene ids to the more consistent ensembl gene IDs that will enhance the accuracy and reproducibility of downstream analyses. :::\n",
    "\n",
    "Between different versions the ensembl gene ids will only change if the gene structure changes. \n",
    "\n",
    "Explain a bit more here? (e.g in newer versions new genes might be added, nothing we can do about it,\n",
    "                            if the gene id is the same the mapped gene region should have stayed the same. -> perfect!\n",
    "                            if the gene id has changed that means the gene structure has changed and we should not use it any more!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load the required libaries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import atlas_protocol_scripts as aps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import yaml\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../../data/results/qc/\"\n",
    "!mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    \"maynard_2020\": \"../../data/input_data_raw/maynard2020.h5ad\",\n",
    "    \"lambrechts_2018\": \"../../data/input_data_raw/lambrechts_2018_luad_6653.h5ad\",\n",
    "    \"ukim-v\": \"../../data/input_data_raw/ukim_v_batch1.h5ad\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {dataset_id: sc.read_h5ad(path) for dataset_id, path in DATASETS.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'maynard_2020': 'X does not contain all integers'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that adata.X contains integers - requirement for scvi-tools integration\n",
    "errors = {}\n",
    "for name, adata in datasets.items():\n",
    "    try:\n",
    "        assert np.all(np.modf(adata.X.data)[0] == 0)\n",
    "    except AssertionError:\n",
    "        errors[name] = \"X does not contain all integers\"\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round length corrected plate-based study\n",
    "datasets[\"maynard_2020\"].X.data = np.ceil(datasets[\"maynard_2020\"].X.data).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Harmonize metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before integrating the data we need to make sure to harmonize the metdata across our datasets. We will start by loading a pre-defined reference metadata yaml file that lists all columns we would like to have as well as the respective values that are allowed in every column. Using a helper function we can now quickly query what metadata is missing and if all values follow the same conventions.\n",
    "\n",
    "(Note: possible to use sfaira for metadata harmonization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the YAML file and load it into a dictionary\n",
    "file_path = \"../../tables/meta_reference.yaml\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    ref_meta_dict = yaml.load(f, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset',\n",
       " 'sample',\n",
       " 'origin',\n",
       " 'tissue',\n",
       " 'condition',\n",
       " 'patient',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'cell_type_salcher',\n",
       " 'platform']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List reference columns from meta yaml file\n",
    "ref_meta_cols = []\n",
    "for key, sub_dict in ref_meta_dict.items():\n",
    "    ref_meta_cols.append(key)\n",
    "ref_meta_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will check if all columns are present across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'maynard_2020': 'Missing columns in adata.obs: dataset, platform',\n",
       " 'lambrechts_2018': \"Invalid values found in column 'dataset': ['lambrechts_2018_luad_6653']\",\n",
       " 'ukim-v': 'Missing columns in adata.obs: dataset, cell_type_salcher, platform'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over datasets and apply validate_obs function\n",
    "invalid_columns = {}\n",
    "for key, adata in datasets.items():\n",
    "    try:\n",
    "        aps.pp.validate_obs(adata, ref_meta_dict)\n",
    "    except ValueError as e:\n",
    "        invalid_columns[key] = e.args[0]\n",
    "invalid_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'condition': {'values': ['LUAD', 'LSCC', 'NSCLC'],\n",
       "  'description': 'Lung adenocarcinoma (LUAD) and lung squamous cell carcinoma (LSCC) are the most common subtypes of non-small-cell lung cancer (NSCLC)'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search reference dict for missing columns\n",
    "aps.pp.search_dict(ref_meta_dict, [\"condition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aps.pp.search_dict(ref_meta_dict, [\"dataset\", \"platform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"maynard_2020\"].obs[\"dataset\"] = \"maynard_2020\"\n",
    "datasets[\"maynard_2020\"].obs[\"platform\"] = \"smartseq2\"\n",
    "\n",
    "datasets[\"ukim-v\"].obs[\"dataset\"] = \"ukim-v\"\n",
    "datasets[\"ukim-v\"].obs[\"platform\"] = \"bd_rhapsody\"\n",
    "datasets[\"ukim-v\"].obs[\"cell_type_salcher\"] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over datasets and apply validate_obs function\n",
    "invalid_columns = {}\n",
    "for key, adata in datasets.items():\n",
    "    try:\n",
    "        aps.pp.validate_obs(\n",
    "            adata,\n",
    "            ref_meta_dict,\n",
    "            keys_to_ignore=[\"dataset\", \"sample\", \"patient\", \"cell_type_salcher\"],\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        invalid_columns[key] = e.args[0]\n",
    "invalid_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will ignore a few columns that contain unique ids as well as cell types - although we could of course define every allowed value in the yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset columns and keep only reference columns from meta yaml file\n",
    "for adata in datasets:\n",
    "    datasets[adata].obs = datasets[adata].obs[ref_meta_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Harmonize gene annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before intgration we want ensembl ids without version numbers as var_names. \n",
    "note: we will have the best match between gene ids and symbols if we use the annotation that was used for mapping, can usually be found in the methods section of the paper or on GEO etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gtf for gene mapping\n",
    "gtf_path = \"../../tables/gencode.v32_gene_annotation_table.csv\"\n",
    "gtf = pd.read_csv(gtf_path)\n",
    "gtf = aps.pp.append_duplicate_suffix(df=gtf, column=\"GeneSymbol\", sep=\"-\")\n",
    "gene_ids = gtf.set_index(\"GeneSymbol\")[\"Geneid\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"lambrechts_2018\"].var = (\n",
    "    datasets[\"lambrechts_2018\"].var.rename_axis(\"symbol\").reset_index()\n",
    ")\n",
    "datasets[\"lambrechts_2018\"].var[\"ensembl\"] = (\n",
    "    datasets[\"lambrechts_2018\"].var[\"symbol\"].map(gene_ids)\n",
    ")\n",
    "datasets[\"lambrechts_2018\"].var_names = (\n",
    "    datasets[\"lambrechts_2018\"].var[\"ensembl\"].apply(aps.pp.remove_gene_version)\n",
    ")\n",
    "\n",
    "datasets[\"maynard_2020\"].var.reset_index(inplace=True)\n",
    "datasets[\"maynard_2020\"].var_names = (\n",
    "    datasets[\"maynard_2020\"].var[\"ensg\"].apply(aps.pp.remove_gene_version)\n",
    ")\n",
    "\n",
    "datasets[\"ukim-v\"].var.reset_index(inplace=True)\n",
    "datasets[\"ukim-v\"].var[\"ensembl\"] = datasets[\"ukim-v\"].var[\"Gene\"].map(gene_ids)\n",
    "datasets[\"ukim-v\"].var_names = (\n",
    "    datasets[\"ukim-v\"].var[\"ensembl\"].apply(aps.pp.remove_gene_version)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maynard_2020 : 0\n",
      "lambrechts_2018 : 0\n",
      "ukim-v : 582\n"
     ]
    }
   ],
   "source": [
    "# look how many genes were not mapped to ensembl ids\n",
    "unmapped_dict = {}\n",
    "for name, data in datasets.items():\n",
    "    unmapped_genes = aps.pp.find_unmapped_genes(data)\n",
    "    print(name, \":\", len(unmapped_genes))\n",
    "    unmapped_dict[name] = unmapped_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove genes without ensembl ids from the datasets\n",
    "datasets[\"ukim-v\"] = datasets[\"ukim-v\"][:, ~(datasets[\"ukim-v\"].var_names == \"nan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate counts with the same id\n",
    "for adata in datasets:\n",
    "    duplicated_ids = (\n",
    "        datasets[adata].var_names[datasets[adata].var_names.duplicated()].unique()\n",
    "    )\n",
    "    datasets[adata] = aps.pp.aggregate_duplicate_gene_ids(\n",
    "        datasets[adata], duplicated_ids\n",
    "    )\n",
    "    assert datasets[adata].var_names.is_unique\n",
    "    assert datasets[adata].obs_names.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean input data by removing not needed data\n",
    "for col in [\"counts_length_scaled\", \"tpm\"]:\n",
    "    del datasets[\"maynard_2020\"].layers[col]\n",
    "\n",
    "del datasets[\"ukim-v\"].obsm[\"surface_protein\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concat datasets to single adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the datasets are ready to be merged. We will also use the latest gene annotation from ensembl to update the gene ids and symbols. We could also use gencode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer join to keep all genes, fill_value=0 assuming that the removed gene expression was 0 or close to zero!\n",
    "adata = anndata.concat(datasets, index_unique=\"_\", join=\"outer\", fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest ensembl annoation to update our genes\n",
    "gtf_path = \"../../tables/Homo_sapiens.GRCh38.109_gene_annotation_table.csv\"\n",
    "gtf = pd.read_csv(gtf_path)\n",
    "gtf[\"ensembl\"] = gtf[\"gene_id\"].apply(aps.pp.remove_gene_version)\n",
    "gtf[\"var_names\"] = gtf[\"gene_name\"].fillna(gtf[\"ensembl\"])\n",
    "gtf = aps.pp.append_duplicate_suffix(df=gtf, column=\"var_names\", sep=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var = pd.merge(\n",
    "    pd.DataFrame({\"ensembl\": adata.var_names}),\n",
    "    gtf,\n",
    "    how=\"left\",\n",
    "    on=\"ensembl\",\n",
    "    validate=\"m:1\",\n",
    ").set_index(\"ensembl\")\n",
    "\n",
    "# Reorder by gtf (i.e. chromosome position)\n",
    "gene_index = gtf[gtf[\"ensembl\"].isin(adata.var_names)][\"ensembl\"].values\n",
    "adata = adata[:, gene_index]\n",
    "\n",
    "adata.var = adata.var.reset_index(\"ensembl\")\n",
    "\n",
    "adata.var_names = adata.var[\"var_names\"].values\n",
    "adata.var_names_make_unique()\n",
    "del adata.var[\"var_names\"]\n",
    "adata.var_names.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure samples are unique\n",
    "adata.obs[\"sample\"] = [\n",
    "    f\"{dataset}_{sample}\"\n",
    "    for dataset, sample in zip(adata.obs[\"dataset\"], adata.obs[\"sample\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append dataset and sample info to barcodes\n",
    "adata.obs_names = (\n",
    "    adata.obs[\"dataset\"].astype(str)\n",
    "    + \"_\"\n",
    "    + adata.obs[\"sample\"].astype(str)\n",
    "    + \"_\"\n",
    "    + adata.obs_names.str.split(\"_\").str[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert adata.var_names.is_unique\n",
    "assert adata.obs_names.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: have a threshold that removes genes if not present in at least 25 percent of studies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Store result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(f\"{out_dir}/adata.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CRCA-2023-crca-scanpy]",
   "language": "python",
   "name": "conda-env-CRCA-2023-crca-scanpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
